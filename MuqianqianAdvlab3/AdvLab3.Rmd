---
title: "Lab3_Muqianqian"
author: "Muqianqian"
date: "2023-11-13"
output:
  html_document: default
  pdf_document: default
---
## Comprehensive exploration of the spatiotemporal nuances
We will using packages like ```ggplot()``` and ```gganimate()``` to explore spatial dimensions ```gganimate``` is an extension of the grammar of graphics, as implemented by the ggplot2 package, that adds support for declaring animations using an API familiar to users of ggplot2.

```{r}
library(readr)
library(ggplot2)
library(ggthemes)
library(gganimate)
library(foreign)
library(dplyr)
library(rnaturalearth)
library(rnaturalearthdata)
library(gifski)
library(lubridate)
#library(tidyverse)
library(wesanderson)
```
1. Open the data.
```{r}
MichFlickr <- read.csv("MichiganFlickr.csv")
```

2. Let us see the distribution of the data. Because I want to plot time series data, and the ```MichiganFlickr.csv``` is not the format I want, so change it into the R understandable data. We do this by coersing it using ```ad.Date``` or ```as.POSIXct``` function. This is part of the package ```Lubridate```, which is helpful for time series data. It can also be used to grab/parse specific parts of a date (e.g year, month etc.)
```{r}
MichFlickr$date <- as.POSIXct(MichFlickr$dateupload, origin="1970-01-01")
MichFlickr$date <- as.Date(format(MichFlickr$date, format="%Y-%m-%d"))
###We will also give it a value. We want to count the number of photos 
MichFlickr$year <- year(MichFlickr$date)
MichFlickr$month <- month(MichFlickr$date, label = TRUE)
MichFlickr$day <- day(MichFlickr$date)
MichFlickr$count<- 1
MichFlickr$Nature<- MichFlickr$predict_Na > 0.6

# and I want to show Landuse = 21 
MichFlickr$land21 <-MichFlickr$Landuse == 21

```


3.To plot time series, we need to summarise the photos per day. In this case, we will use the *mutate*,*group_by* and summarise function to create a new table.
```{r}
daily_photography<- MichFlickr %>%
  mutate(day = as.Date(date, format="%Y-%m-%d")) %>%
  group_by(day) %>% # group by the day column
  summarise(total_photos=sum(count)) %>%  
  # calculate the SUM of all precipitation that occurred on each day
  # omit all unnecessary cases from data frame, matrix or vector.
  na.omit()
head(daily_photography)
```

4. Now plot the data.
- first is graph the data between 2005 and 2010 and smooth the data to see the trend of photographic sharing for Michigan by using spline function.

```{r}

p <- ggplot(daily_photography, aes(x = day, y = total_photos)) +
  geom_line(color = "#00AFBB", size = 1) + 
  scale_x_date(date_labels = "%b")

## set the minimum and maximum to omit 
min <- as.Date("2005-1-1")
max <- as.Date("2010-12-31")

# set the axis limits c(min, max)
p + scale_x_date(limits=c(min,max))+
  geom_smooth(method = lm, formula = y ~ splines::bs(x, 3), se = FALSE)

```

- And then graph in different categories of data at the same time. When viewing the datasheet I want to categories the data by using land use.I just chose one of the landuse equal 21 to make a new column 

```{r}
daily_landuse <- MichFlickr %>%
  mutate(day = as.Date(date, format="%Y-%m-%d")) %>%
  group_by(day, land21) %>% # group by the day column
  summarise(total_photos=sum(count)) 


ggplot(daily_landuse, aes(x = day, y = total_photos)) + 
  geom_line(aes(color = land21), size = 1) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_x_date(limits = c(min, max)) +
  theme_minimal()


```

By seeing this chart, I can get a valid reasonable support that between 2005 to 2010 the from the graph that landuse type 21 is the main landuse type in Michigan State.

- And we can also summarized the data in to another dataframe.Plotting the data through monthly pattern of sharing photograph through Flicker. And I am going to use the lubridate```function``` to grab the data.

```{r}
daily_monthly <- daily_photography %>%
    mutate(month =  month(ymd(daily_photography$day), label = TRUE, abbr = FALSE),
           year  = year(as.Date(day, format = "%Y-%m-%d"))) %>%
    group_by(year,month) %>%
    summarise(total.qty = sum(total_photos)) 
daily_monthly
```

Then plot the data we wanted. I plot different years of photography by month between 2005 to 2011.
```{r}
daily_monthly  %>%
    filter(year > 2004)  %>% 
    filter(year < 2011)  %>% 
    ggplot(aes(x = month, y = total.qty, group = year)) +
    geom_line(aes(color = as.factor(year))) +
    scale_color_discrete() + 
    labs(title = "Total Flickr Photographs for Michigan", x = "", y = "Total Photographs",
         subtitle = "Activity is highest for the summer months") +
   theme_classic()
```

-Animating spatial data
```{r}
######Data for Michigan
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
states <- map_data("state")
mich <- subset(states, region == "michigan")
counties <- map_data("county")
mich_county <- subset(counties, region == "michigan")
mich <- ggplot(data = mich, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "orange")
mich

```

Then add the counties and omit the gradicule.
```{r}
mich+theme_void() + 
  geom_polygon(data = mich_county, fill = NA, color = "white") +
  geom_polygon(color = "black", fill = NA)  # get the state border back on top
```

And then process the data I want to animate.
```{r}
MichFlickr$date <- as.Date(as.POSIXct(MichFlickr$dateupload, origin="1970-01-01"))
MichFlickr$date <- as.Date(format(MichFlickr$date, format="%Y-%m-%d"))
animateMich <- MichFlickr %>% 
  filter( date >= as.Date('2011-01-01') & date <= as.Date('2011-12-31'))
```

- Now we can plot the animation map.
```{r}
p2 <-mich + theme_void() + 
        geom_polygon(data = mich_county, fill = NA, color = "white") +
        geom_polygon(color = "black", fill = NA) + 
        
       geom_point(data = animateMich, aes(longitude, latitude), inherit.aes = FALSE) +
        labs(title = 'Date: {format(frame_time, "%b %d %Y")}') +
        transition_time(date) 

animate(p2 + shadow_wake(0.1), fps=2)
#animate(p2 + shadow_wake(0.1, size = 1, alpha = FALSE, colour = 'grey92'), fps=2)
```
SO the argument I have is landuse21 is the most widespread land use type in Michigan according to the plot above.

## Develop a technique for noise reduction

Sometimes, the quality of the photos are so low that we can not distinguish the image categories. To avoid these data influence other data analyze, we should remove them from the dataset. And I am using ```magrittr``` ```imager``` and ```magick``` to help me filter the data quality.

```{r}
knitr::include_graphics("C:/Users/Lenovo/Documents/MuqianqianAdvlab3/method.png")
```

Because the image is too much and too long to proceed this method, so I give a screen shot of the code and choose to do not run it.
In this example, the download_and_check_quality function takes a URL, downloads the image to a temporary file, checks the image quality, and then removes the temporary file. The filter process is then applied to your data frame, and you can save the filtered images to a CSV file if necessary.
As you can see I develop a method to filter out low image quality data and In this code, width(img) and height(img) directly extract the width and height of the image, respectively. The rest of the code remains similar. 
In this process, the low quality data can be filter out from the data set. And after filtering all the database, the low quality image will be out of dataset and the analyze will be more accurate than before because losing some fuzz images.
